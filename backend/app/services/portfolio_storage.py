"""Portfolio persistence utilities.

Implements the portable-first storage design for generation history:
- Single SQLite database that lives in the Sweet Tea meta directory.
- Media referenced via relative paths so the DB + media folder can move together.
- Thumbnails stored inline for lightweight previews, with originals on disk.
- Provenance embedded into output images so files remain self-describing.
- Export/import helpers that ship only the database plus a manifest.
"""
from __future__ import annotations

import io
import json
import sqlite3
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional
from zipfile import ZIP_DEFLATED, ZipFile

from PIL import Image, ImageOps, PngImagePlugin
from sqlmodel import Session, select

from app.core.config import settings
from app.models.portfolio import (
    ComfyWorkflow,
    ModelCatalog,
    Output,
    Pipe,
    Run,
    RunModelLink,
)


@dataclass
class ModelUsage:
    """Represents a model used during a run."""

    role: str  # checkpoint, lora, control, vae, etc.
    kind: str
    name: str
    path: Path
    checksum: Optional[str] = None
    metadata: Optional[Dict[str, Any]] = None


@dataclass
class OutputArtifact:
    """Represents an artifact generated by a run."""

    path: Path
    kind: str
    index: int
    metadata: Optional[Dict[str, Any]] = None
    perceptual_hash: Optional[str] = None
    embed_provenance: bool = True


def _relative_path(path: Path, root: Path) -> str:
    """Return a path relative to ``root`` to keep database rows portable."""

    try:
        return str(path.resolve().relative_to(root.resolve()))
    except ValueError as exc:  # pragma: no cover - defensive guard
        raise ValueError(f"Path {path} must be inside root {root}") from exc


def _create_thumbnail(image_path: Path, max_px: int = 256, quality: int = 45) -> bytes:
    """Generate a compact JPEG thumbnail suitable for inline DB storage."""

    with Image.open(image_path) as img:
        img = ImageOps.exif_transpose(img)
        img.thumbnail((max_px, max_px))
        if img.mode in {"RGBA", "P"}:
            img = img.convert("RGB")
        buffer = io.BytesIO()
        img.save(buffer, format="JPEG", quality=quality, optimize=True)
        return buffer.getvalue()


def _embed_provenance(image_path: Path, payload: Dict[str, Any]) -> None:
    """
    Embed provenance JSON into an image comment/metadata block.

    PNG files receive a text chunk; JPEGs receive a comment segment. Other
    formats are left untouched to avoid corruption.
    """

    provenance_json = json.dumps(payload, ensure_ascii=False)
    with Image.open(image_path) as img:
        fmt = (img.format or "PNG").upper()
        if fmt == "PNG":
            png_info = PngImagePlugin.PngInfo()
            for key, value in img.info.items():
                if isinstance(value, str):
                    png_info.add_text(key, value)
            png_info.add_text("sweet_tea_provenance", provenance_json)
            img.save(image_path, pnginfo=png_info)
        elif fmt in {"JPEG", "JPG"}:
            if img.mode in {"RGBA", "P"}:
                img = img.convert("RGB")
            img.save(image_path, format="JPEG", quality=95, optimize=True, comment=provenance_json.encode("utf-8"))
        else:
            # Leave other formats untouched to avoid breaking non-image assets
            return


def _vacuum_database(db_path: Path) -> None:
    """Compact the SQLite database before exporting."""

    with sqlite3.connect(db_path) as conn:
        conn.execute("VACUUM;")
        conn.commit()


class PortfolioStorage:
    """Utility class for recording runs and exporting/importing the portfolio DB."""

    def __init__(self, *, root_dir: Optional[Path] = None):
        self.root_dir = root_dir or settings.ROOT_DIR
        self.db_path = settings.database_path

    # --- Recording helpers -------------------------------------------------
    def _get_or_create_workflow(self, session: Session, comfy_hash: str, comfy_json: str) -> ComfyWorkflow:
        workflow = session.exec(select(ComfyWorkflow).where(ComfyWorkflow.comfy_hash == comfy_hash)).first()
        if workflow:
            return workflow
        workflow = ComfyWorkflow(comfy_hash=comfy_hash, comfy_json=comfy_json)
        session.add(workflow)
        session.commit()
        session.refresh(workflow)
        return workflow

    def _get_or_create_pipe(
        self,
        session: Session,
        *,
        slug: str,
        name: Optional[str],
        workflow_id: int,
        default_params: Dict[str, Any],
        description: Optional[str] = None,
    ) -> Pipe:
        pipe = session.exec(select(Pipe).where(Pipe.slug == slug)).first()
        if pipe:
            return pipe
        pipe = Pipe(
            name=name or slug,
            slug=slug,
            workflow_id=workflow_id,
            default_params=json.dumps(default_params or {}),
            description=description,
        )
        session.add(pipe)
        session.commit()
        session.refresh(pipe)
        return pipe

    def _register_models(self, session: Session, models: Iterable[ModelUsage]) -> List[RunModelLink]:
        links: List[RunModelLink] = []
        for model in models:
            relative_path = _relative_path(model.path, self.root_dir)
            existing = session.exec(
                select(ModelCatalog).where(
                    ModelCatalog.path == relative_path, ModelCatalog.kind == model.kind
                )
            ).first()

            if existing:
                existing.last_used_at = datetime.utcnow()
                catalog = existing
            else:
                catalog = ModelCatalog(
                    kind=model.kind,
                    name=model.name,
                    path=relative_path,
                    checksum=model.checksum,
                    meta_json=json.dumps(model.metadata or {}),
                    last_used_at=datetime.utcnow(),
                )
                session.add(catalog)
                session.commit()
                session.refresh(catalog)

            links.append(
                RunModelLink(run_id=0, model_id=catalog.id, role=model.role)  # run_id updated after run is created
            )
        return links

    def _prepare_provenance_payload(
        self,
        *,
        pipe_slug: str,
        comfy_hash: str,
        prompts: Dict[str, Any],
        params: Dict[str, Any],
        models: Iterable[ModelUsage],
        run: Run,
    ) -> Dict[str, Any]:
        return {
            "pipe_slug": pipe_slug,
            "comfy_hash": comfy_hash,
            "positive_prompt": prompts.get("positive"),
            "negative_prompt": prompts.get("negative"),
            "seed": run.seed,
            "steps": run.steps,
            "cfg": run.cfg,
            "sampler": run.sampler,
            "engine_name": run.engine_name,
            "engine_version": run.engine_version,
            "app_version": run.app_version,
            "duration_ms": run.duration_ms,
            "final_iterations_per_second": run.final_iterations_per_second,
            "params": params,
            "models": [
                {
                    "role": model.role,
                    "kind": model.kind,
                    "name": model.name,
                    "path": _relative_path(model.path, self.root_dir),
                    "checksum": model.checksum,
                }
                for model in models
            ],
        }

    def record_run(
        self,
        session: Session,
        *,
        run_uuid: str,
        comfy_hash: str,
        comfy_json: str,
        pipe_slug: str,
        pipe_name: Optional[str],
        params_diff: Dict[str, Any],
        default_params: Dict[str, Any],
        prompts: Dict[str, Any],
        outputs: Iterable[OutputArtifact],
        models: Iterable[ModelUsage],
        project_id: Optional[int] = None,
        workflow_description: Optional[str] = None,
        sampler: Optional[str] = None,
        seed: Optional[str] = None,
        steps: Optional[int] = None,
        cfg: Optional[float] = None,
        scale_factor: Optional[float] = None,
        width: Optional[int] = None,
        height: Optional[int] = None,
        duration_ms: Optional[int] = None,
        final_iterations_per_second: Optional[float] = None,
        engine_name: Optional[str] = None,
        engine_version: Optional[str] = None,
        status: str = "success",
    ) -> Run:
        """
        Persist a complete generation run and its outputs.

        The method deduplicates comfy workflows, pipes, and models, embeds
        provenance into output images, and stores lightweight thumbnails for
        quick recall even when originals are unavailable.
        """

        workflow = self._get_or_create_workflow(session, comfy_hash, comfy_json)
        pipe = self._get_or_create_pipe(
            session,
            slug=pipe_slug,
            name=pipe_name,
            workflow_id=workflow.id,
            default_params=default_params,
            description=workflow_description,
        )

        model_links = self._register_models(session, models)

        run = Run(
            run_uuid=run_uuid,
            project_id=project_id,
            pipe_id=pipe.id,
            workflow_id=workflow.id,
            positive_prompt=prompts.get("positive"),
            negative_prompt=prompts.get("negative"),
            width=width,
            height=height,
            scale_factor=scale_factor,
            seed=seed,
            steps=steps,
            cfg=cfg,
            sampler=sampler,
            status=status,
            duration_ms=duration_ms,
            final_iterations_per_second=final_iterations_per_second,
            engine_name=engine_name,
            engine_version=engine_version,
            app_version=settings.APP_VERSION,
            params_json=json.dumps(params_diff or {}),
        )
        session.add(run)
        session.commit()
        session.refresh(run)

        # Now that run exists, backfill run_id on model links and persist
        for link in model_links:
            link.run_id = run.id
            session.add(link)
        session.commit()

        provenance_payload = self._prepare_provenance_payload(
            pipe_slug=pipe.slug,
            comfy_hash=comfy_hash,
            prompts=prompts,
            params=params_diff,
            models=models,
            run=run,
        )

        for artifact in outputs:
            relative_path = _relative_path(artifact.path, self.root_dir)
            thumb = None
            if artifact.kind == "image" and artifact.path.exists():
                thumb = _create_thumbnail(artifact.path)
                if artifact.embed_provenance:
                    _embed_provenance(artifact.path, provenance_payload)

            output_row = Output(
                run_id=run.id,
                kind=artifact.kind,
                index_in_run=artifact.index,
                path=relative_path,
                thumb_jpeg=thumb,
                perceptual_hash=artifact.perceptual_hash,
                meta_json=json.dumps(artifact.metadata or {}),
            )
            session.add(output_row)
        session.commit()

        return run

    # --- Export/import helpers --------------------------------------------
    def export_database(self, export_path: Path, *, include_manifest: Optional[Dict[str, Any]] = None) -> Path:
        """Vacuum the DB then zip it with a manifest (excluding media)."""

        _vacuum_database(self.db_path)
        manifest = {
            "exported_at": datetime.utcnow().isoformat(),
            "app_version": settings.APP_VERSION,
            "database": self.db_path.name,
        }
        if include_manifest:
            manifest.update(include_manifest)

        export_path.parent.mkdir(parents=True, exist_ok=True)
        with ZipFile(export_path, "w", compression=ZIP_DEFLATED) as zip_file:
            zip_file.write(self.db_path, arcname=self.db_path.name)
            zip_file.writestr("manifest.json", json.dumps(manifest, indent=2))
        return export_path

    def import_database(self, archive_path: Path) -> Path:
        """
        Import a zipped database + manifest into the Sweet Tea meta directory.

        The DB is extracted to ``settings.meta_dir``. Media paths stay valid
        because rows use relative paths.
        """

        with ZipFile(archive_path, "r") as zip_file:
            zip_file.extractall(settings.meta_dir)
        return settings.database_path
